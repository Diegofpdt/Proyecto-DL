{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEvbCzrTWb7Y",
        "outputId": "5241118f-47fe-45a7-dbfa-0e9dd6873526"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.2.0 sacrebleu-2.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oraciones en ingles\n",
        "with open(\"eng.txt\", \"r\", encoding=\"utf-8\") as eng:\n",
        "  source_sentences = eng.read().strip().split(\"\\n\")\n",
        "\n",
        "# Referencias correctas (gallego)\n",
        "with open(\"glg.txt\", \"r\", encoding=\"utf-8\") as glg:\n",
        "  references = glg.read().strip().split(\"\\n\")"
      ],
      "metadata": {
        "id": "xaNZN3d_b3Km"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# Cargar modelo y tokenizador\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Configurar idioma de origen\n",
        "tokenizer.src_lang = \"en\"\n",
        "\n",
        "translations = []\n",
        "\n",
        "for sentence in source_sentences:\n",
        "    # Tokenizar\n",
        "    encoded = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    # Traducir al gallego\n",
        "    generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(\"gl\"))\n",
        "    translated = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
        "    translations.append(translated)\n",
        "\n",
        "print(\"Traducciones:\")\n",
        "for t in translations[:5]:\n",
        "    print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "pBa7kW8TbIxu",
        "outputId": "c7846d23-80fb-424d-870b-505baf0a540c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traducciones:\n",
            "\"Agora temos ratos de 4 meses que non son diabéticos que adoitan ser diabéticos\", engadiu.\n",
            "Ehud Ur, profesor de medicina na Universidade Dalhousie en Halifax, Nova Escocia e presidente da división clínica e científica da Asociación Canadiense de Diabetes, advertiu que a investigación aínda está nos seus primeiros días.\n",
            "Como algúns outros expertos, é escéptico sobre se a diabetes pode ser curada, notando que estes resultados non teñen relevancia para as persoas que xa teñen diabetes tipo 1.\n",
            "O luns, Sara Danius, secretaria permanente do Comité Nobel de Literatura na Academia Sueca, anunciou publicamente durante un programa de radio en Sveriges Radio en Suecia que o comité, incapaz de chegar a Bob Dylan directamente sobre gañar o Premio Nobel de Literatura de 2016, abandonou os seus esforzos para chegar a el.\n",
            "Danius dixo: \"Agora non estamos facendo nada, chamei e enviei correos electrónicos ao seu colaborador máis próximo e recibín respostas moi amigables.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "# BLEU\n",
        "bleu = sacrebleu.corpus_bleu(translations, [references])\n",
        "print(f\"BLEU score: {bleu.score:.2f}\")\n",
        "\n",
        "# chrF\n",
        "chrf = sacrebleu.corpus_chrf(translations, [references])\n",
        "print(f\"chrF score: {chrf.score:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRppWenrbMwy",
        "outputId": "32b975a2-cccd-4330-8cb0-3a03921ceb4a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score: 27.32\n",
            "chrF score: 57.09\n"
          ]
        }
      ]
    }
  ]
}